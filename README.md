🏛️ SmartMuseum — BME Hackathon 2025
SmartMuseum is an IoT-powered museum assistant designed to enrich visitor engagement with physical exhibitions through proximity sensing and AI interaction. Created during the BME Hackathon 2025, the project combines real-time visitor tracking, personalized exhibit suggestions, and interactive voice-based Q&A to create an intelligent museum experience.

🚀 Project Goals
Make museums more interactive and accessible using low-cost technology.

Track user interest in exhibits and trigger actions (like audio or visual cues).

Enable voice-based interaction using AI to answer questions about art pieces.

Deliver personalized recommendations based on user behavior.



🧠 Key Features
🎯 Proximity-Based Exhibit Detection: Uses camera input or BLE sensors to detect if a user is observing an exhibit.

🗣️ Voice-Activated AI Assistant: After an audio prompt, users can ask questions. Speech-to-text and OpenAI APIs generate a spoken response.

🖼️ Time Tracking: Monitors how long a visitor views each piece, triggering information delivery if the user stays for a defined period.



🛠️ Tech Stack
Layer	Technologies Used
Frontend	HTML, CSS, JavaScript (vanilla)
Backend	Python (Flask or local scripts)
AI/Voice	OpenAI GPT API, Web Speech API, TTS
Sensors	Camera for detection / BLE for presence
