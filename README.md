ğŸ›ï¸ SmartMuseum â€” BME Hackathon 2025
SmartMuseum is an IoT-powered museum assistant designed to enrich visitor engagement with physical exhibitions through proximity sensing and AI interaction. Created during the BME Hackathon 2025, the project combines real-time visitor tracking, personalized exhibit suggestions, and interactive voice-based Q&A to create an intelligent museum experience.

ğŸš€ Project Goals
Make museums more interactive and accessible using low-cost technology.

Track user interest in exhibits and trigger actions (like audio or visual cues).

Enable voice-based interaction using AI to answer questions about art pieces.

Deliver personalized recommendations based on user behavior.



ğŸ§  Key Features
ğŸ¯ Proximity-Based Exhibit Detection: Uses camera input or BLE sensors to detect if a user is observing an exhibit.

ğŸ—£ï¸ Voice-Activated AI Assistant: After an audio prompt, users can ask questions. Speech-to-text and OpenAI APIs generate a spoken response.

ğŸ–¼ï¸ Time Tracking: Monitors how long a visitor views each piece, triggering information delivery if the user stays for a defined period.



ğŸ› ï¸ Tech Stack
Layer	Technologies Used
Frontend	HTML, CSS, JavaScript (vanilla)
Backend	Python (Flask or local scripts)
AI/Voice	OpenAI GPT API, Web Speech API, TTS
Sensors	Camera for detection / BLE for presence
